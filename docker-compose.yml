version: "3.8"

services:
  web_server:
    build:
      context: ./rtc
      # dockerfile: ./rtc/Dockerfile
    ports:
      - "8088:8088"

  audio_client_parser:
    restart: "on-failure"
    build:
      context: ./client
      # dockerfile: ./client/Dockerfile
    depends_on:
      - web_server
      - transcription_service
    environment:
      URL: web_server:8088
      ROOM: test
      TRANSCRIPTION_SERVICE: http://transcription_service:8000/

  transcription_service:
    restart: "on-failure"
    build:
      context: ./stt/servers/faster-whisper-api
      # dockerfile: ./stt/servers/faster-whisper-api/Dockerfile
      args:
        MODEL_SIZE: medium
        MODEL_DEVICE: cuda
        MODEL_COMPUTE_TYPE: float16
    environment:
      MODEL_SIZE: medium
      MODEL_DEVICE: cuda
      MODEL_COMPUTE_TYPE: float16
    depends_on:
      - web_server
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
